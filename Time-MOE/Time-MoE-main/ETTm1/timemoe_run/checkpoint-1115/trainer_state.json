{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9997758350145707,
  "eval_steps": 500,
  "global_step": 1115,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0008966599417171038,
      "grad_norm": 0.33923786878585815,
      "learning_rate": 9.999990076617395e-05,
      "loss": 0.1132,
      "step": 1
    },
    {
      "epoch": 0.008966599417171038,
      "grad_norm": 0.1582304835319519,
      "learning_rate": 9.999007726730326e-05,
      "loss": 0.1029,
      "step": 10
    },
    {
      "epoch": 0.017933198834342075,
      "grad_norm": 0.08577774465084076,
      "learning_rate": 9.996031694606295e-05,
      "loss": 0.093,
      "step": 20
    },
    {
      "epoch": 0.026899798251513115,
      "grad_norm": 0.0830039381980896,
      "learning_rate": 9.99107426605761e-05,
      "loss": 0.0868,
      "step": 30
    },
    {
      "epoch": 0.03586639766868415,
      "grad_norm": 0.0568804033100605,
      "learning_rate": 9.984139376383337e-05,
      "loss": 0.0809,
      "step": 40
    },
    {
      "epoch": 0.04483299708585519,
      "grad_norm": 0.045049864798784256,
      "learning_rate": 9.975232530627998e-05,
      "loss": 0.078,
      "step": 50
    },
    {
      "epoch": 0.05379959650302623,
      "grad_norm": 0.03528836369514465,
      "learning_rate": 9.964360799211563e-05,
      "loss": 0.0741,
      "step": 60
    },
    {
      "epoch": 0.06276619592019726,
      "grad_norm": 0.03993597999215126,
      "learning_rate": 9.951532812316813e-05,
      "loss": 0.071,
      "step": 70
    },
    {
      "epoch": 0.0717327953373683,
      "grad_norm": 0.04502749815583229,
      "learning_rate": 9.936758753038551e-05,
      "loss": 0.0686,
      "step": 80
    },
    {
      "epoch": 0.08069939475453934,
      "grad_norm": 0.046393029391765594,
      "learning_rate": 9.92005034930006e-05,
      "loss": 0.0663,
      "step": 90
    },
    {
      "epoch": 0.08966599417171038,
      "grad_norm": 0.1057286262512207,
      "learning_rate": 9.901420864543265e-05,
      "loss": 0.0646,
      "step": 100
    },
    {
      "epoch": 0.09863259358888142,
      "grad_norm": 0.06946899741888046,
      "learning_rate": 9.880885087199971e-05,
      "loss": 0.0637,
      "step": 110
    },
    {
      "epoch": 0.10759919300605246,
      "grad_norm": 0.06500817090272903,
      "learning_rate": 9.858459318952521e-05,
      "loss": 0.063,
      "step": 120
    },
    {
      "epoch": 0.1165657924232235,
      "grad_norm": 0.04208524152636528,
      "learning_rate": 9.834161361793221e-05,
      "loss": 0.0617,
      "step": 130
    },
    {
      "epoch": 0.12553239184039452,
      "grad_norm": 0.05488390475511551,
      "learning_rate": 9.808010503892788e-05,
      "loss": 0.0606,
      "step": 140
    },
    {
      "epoch": 0.13449899125756556,
      "grad_norm": 0.062482405453920364,
      "learning_rate": 9.780027504289042e-05,
      "loss": 0.0597,
      "step": 150
    },
    {
      "epoch": 0.1434655906747366,
      "grad_norm": 0.028062153607606888,
      "learning_rate": 9.750234576407994e-05,
      "loss": 0.0589,
      "step": 160
    },
    {
      "epoch": 0.15243219009190764,
      "grad_norm": 0.03977947309613228,
      "learning_rate": 9.718655370430411e-05,
      "loss": 0.0585,
      "step": 170
    },
    {
      "epoch": 0.16139878950907868,
      "grad_norm": 0.053103722631931305,
      "learning_rate": 9.68531495451787e-05,
      "loss": 0.058,
      "step": 180
    },
    {
      "epoch": 0.17036538892624972,
      "grad_norm": 0.052291955798864365,
      "learning_rate": 9.650239794913177e-05,
      "loss": 0.0572,
      "step": 190
    },
    {
      "epoch": 0.17933198834342076,
      "grad_norm": 0.035614874213933945,
      "learning_rate": 9.613457734930978e-05,
      "loss": 0.057,
      "step": 200
    },
    {
      "epoch": 0.1882985877605918,
      "grad_norm": 0.05003225803375244,
      "learning_rate": 9.574997972855212e-05,
      "loss": 0.0561,
      "step": 210
    },
    {
      "epoch": 0.19726518717776284,
      "grad_norm": 0.034743066877126694,
      "learning_rate": 9.534891038760971e-05,
      "loss": 0.0559,
      "step": 220
    },
    {
      "epoch": 0.20623178659493388,
      "grad_norm": 0.0337313748896122,
      "learning_rate": 9.49316877027916e-05,
      "loss": 0.0556,
      "step": 230
    },
    {
      "epoch": 0.21519838601210492,
      "grad_norm": 0.05382617935538292,
      "learning_rate": 9.449864287323189e-05,
      "loss": 0.0548,
      "step": 240
    },
    {
      "epoch": 0.22416498542927596,
      "grad_norm": 0.02429795265197754,
      "learning_rate": 9.405011965797774e-05,
      "loss": 0.0546,
      "step": 250
    },
    {
      "epoch": 0.233131584846447,
      "grad_norm": 0.037449244409799576,
      "learning_rate": 9.358647410310704e-05,
      "loss": 0.0545,
      "step": 260
    },
    {
      "epoch": 0.242098184263618,
      "grad_norm": 0.03783509135246277,
      "learning_rate": 9.310807425909231e-05,
      "loss": 0.0541,
      "step": 270
    },
    {
      "epoch": 0.25106478368078905,
      "grad_norm": 0.0471314936876297,
      "learning_rate": 9.261529988863552e-05,
      "loss": 0.0537,
      "step": 280
    },
    {
      "epoch": 0.2600313830979601,
      "grad_norm": 0.0534336119890213,
      "learning_rate": 9.210854216520529e-05,
      "loss": 0.0534,
      "step": 290
    },
    {
      "epoch": 0.26899798251513113,
      "grad_norm": 0.027018379420042038,
      "learning_rate": 9.158820336251616e-05,
      "loss": 0.0529,
      "step": 300
    },
    {
      "epoch": 0.27796458193230217,
      "grad_norm": 0.08223441243171692,
      "learning_rate": 9.105469653519617e-05,
      "loss": 0.0529,
      "step": 310
    },
    {
      "epoch": 0.2869311813494732,
      "grad_norm": 0.037706028670072556,
      "learning_rate": 9.05084451908965e-05,
      "loss": 0.0527,
      "step": 320
    },
    {
      "epoch": 0.29589778076664425,
      "grad_norm": 0.0532720573246479,
      "learning_rate": 8.994988295410312e-05,
      "loss": 0.0524,
      "step": 330
    },
    {
      "epoch": 0.3048643801838153,
      "grad_norm": 0.018325088545680046,
      "learning_rate": 8.937945322191764e-05,
      "loss": 0.0519,
      "step": 340
    },
    {
      "epoch": 0.3138309796009863,
      "grad_norm": 0.0813697874546051,
      "learning_rate": 8.879760881208042e-05,
      "loss": 0.0518,
      "step": 350
    },
    {
      "epoch": 0.32279757901815737,
      "grad_norm": 0.03681284934282303,
      "learning_rate": 8.82048116035155e-05,
      "loss": 0.0518,
      "step": 360
    },
    {
      "epoch": 0.3317641784353284,
      "grad_norm": 0.20558404922485352,
      "learning_rate": 8.760153216968236e-05,
      "loss": 0.0515,
      "step": 370
    },
    {
      "epoch": 0.34073077785249944,
      "grad_norm": 0.04027889668941498,
      "learning_rate": 8.69882494050261e-05,
      "loss": 0.0514,
      "step": 380
    },
    {
      "epoch": 0.3496973772696705,
      "grad_norm": 0.038089051842689514,
      "learning_rate": 8.636545014482197e-05,
      "loss": 0.0512,
      "step": 390
    },
    {
      "epoch": 0.3586639766868415,
      "grad_norm": 0.03381791338324547,
      "learning_rate": 8.573362877871665e-05,
      "loss": 0.051,
      "step": 400
    },
    {
      "epoch": 0.36763057610401256,
      "grad_norm": 0.039600275456905365,
      "learning_rate": 8.509328685827233e-05,
      "loss": 0.0509,
      "step": 410
    },
    {
      "epoch": 0.3765971755211836,
      "grad_norm": 0.02975466661155224,
      "learning_rate": 8.444493269882591e-05,
      "loss": 0.0508,
      "step": 420
    },
    {
      "epoch": 0.38556377493835464,
      "grad_norm": 0.03657795861363411,
      "learning_rate": 8.378908097597875e-05,
      "loss": 0.0506,
      "step": 430
    },
    {
      "epoch": 0.3945303743555257,
      "grad_norm": 0.0530552938580513,
      "learning_rate": 8.312625231703761e-05,
      "loss": 0.0505,
      "step": 440
    },
    {
      "epoch": 0.4034969737726967,
      "grad_norm": 0.029682479798793793,
      "learning_rate": 8.245697288773103e-05,
      "loss": 0.05,
      "step": 450
    },
    {
      "epoch": 0.41246357318986776,
      "grad_norm": 0.03617947921156883,
      "learning_rate": 8.178177397452907e-05,
      "loss": 0.0503,
      "step": 460
    },
    {
      "epoch": 0.4214301726070388,
      "grad_norm": 0.05855429545044899,
      "learning_rate": 8.110119156289842e-05,
      "loss": 0.0499,
      "step": 470
    },
    {
      "epoch": 0.43039677202420984,
      "grad_norm": 0.026904884725809097,
      "learning_rate": 8.041576591182692e-05,
      "loss": 0.0498,
      "step": 480
    },
    {
      "epoch": 0.4393633714413809,
      "grad_norm": 0.025806568562984467,
      "learning_rate": 7.972604112495613e-05,
      "loss": 0.0495,
      "step": 490
    },
    {
      "epoch": 0.4483299708585519,
      "grad_norm": 0.04112313687801361,
      "learning_rate": 7.90325647186616e-05,
      "loss": 0.0496,
      "step": 500
    },
    {
      "epoch": 0.45729657027572296,
      "grad_norm": 0.046427223831415176,
      "learning_rate": 7.833588718742423e-05,
      "loss": 0.0493,
      "step": 510
    },
    {
      "epoch": 0.466263169692894,
      "grad_norm": 0.030489327386021614,
      "learning_rate": 7.763656156683747e-05,
      "loss": 0.0495,
      "step": 520
    },
    {
      "epoch": 0.475229769110065,
      "grad_norm": 0.028203202411532402,
      "learning_rate": 7.693514299459741e-05,
      "loss": 0.0492,
      "step": 530
    },
    {
      "epoch": 0.484196368527236,
      "grad_norm": 0.04880332946777344,
      "learning_rate": 7.623218826982411e-05,
      "loss": 0.049,
      "step": 540
    },
    {
      "epoch": 0.49316296794440706,
      "grad_norm": 0.04041271656751633,
      "learning_rate": 7.552825541106414e-05,
      "loss": 0.0491,
      "step": 550
    },
    {
      "epoch": 0.5021295673615781,
      "grad_norm": 0.05730012431740761,
      "learning_rate": 7.4823903213325e-05,
      "loss": 0.0488,
      "step": 560
    },
    {
      "epoch": 0.5110961667787491,
      "grad_norm": 0.07724114507436752,
      "learning_rate": 7.411969080449328e-05,
      "loss": 0.0489,
      "step": 570
    },
    {
      "epoch": 0.5200627661959202,
      "grad_norm": 0.053396888077259064,
      "learning_rate": 7.341617720148859e-05,
      "loss": 0.0487,
      "step": 580
    },
    {
      "epoch": 0.5290293656130912,
      "grad_norm": 0.03971477597951889,
      "learning_rate": 7.271392086650537e-05,
      "loss": 0.0486,
      "step": 590
    },
    {
      "epoch": 0.5379959650302623,
      "grad_norm": 0.035627782344818115,
      "learning_rate": 7.201347926369537e-05,
      "loss": 0.0484,
      "step": 600
    },
    {
      "epoch": 0.5469625644474333,
      "grad_norm": 0.04657669737935066,
      "learning_rate": 7.131540841664214e-05,
      "loss": 0.0486,
      "step": 610
    },
    {
      "epoch": 0.5559291638646043,
      "grad_norm": 0.03494064137339592,
      "learning_rate": 7.062026246697919e-05,
      "loss": 0.0484,
      "step": 620
    },
    {
      "epoch": 0.5648957632817754,
      "grad_norm": 0.043867338448762894,
      "learning_rate": 6.992859323450201e-05,
      "loss": 0.0482,
      "step": 630
    },
    {
      "epoch": 0.5738623626989464,
      "grad_norm": 0.030669404193758965,
      "learning_rate": 6.924094977912325e-05,
      "loss": 0.0482,
      "step": 640
    },
    {
      "epoch": 0.5828289621161175,
      "grad_norm": 0.019132256507873535,
      "learning_rate": 6.855787796501883e-05,
      "loss": 0.0479,
      "step": 650
    },
    {
      "epoch": 0.5917955615332885,
      "grad_norm": 0.02271147258579731,
      "learning_rate": 6.787992002731063e-05,
      "loss": 0.048,
      "step": 660
    },
    {
      "epoch": 0.6007621609504595,
      "grad_norm": 0.045595310628414154,
      "learning_rate": 6.72076141416303e-05,
      "loss": 0.0481,
      "step": 670
    },
    {
      "epoch": 0.6097287603676306,
      "grad_norm": 0.05946329981088638,
      "learning_rate": 6.654149399690538e-05,
      "loss": 0.0478,
      "step": 680
    },
    {
      "epoch": 0.6186953597848016,
      "grad_norm": 0.04853604733943939,
      "learning_rate": 6.588208837170706e-05,
      "loss": 0.0479,
      "step": 690
    },
    {
      "epoch": 0.6276619592019727,
      "grad_norm": 0.03276963159441948,
      "learning_rate": 6.522992071449595e-05,
      "loss": 0.0477,
      "step": 700
    },
    {
      "epoch": 0.6366285586191437,
      "grad_norm": 0.06911557912826538,
      "learning_rate": 6.458550872809895e-05,
      "loss": 0.0478,
      "step": 710
    },
    {
      "epoch": 0.6455951580363147,
      "grad_norm": 0.02529706247150898,
      "learning_rate": 6.3949363958747e-05,
      "loss": 0.0476,
      "step": 720
    },
    {
      "epoch": 0.6545617574534858,
      "grad_norm": 0.10420744121074677,
      "learning_rate": 6.332199139000039e-05,
      "loss": 0.0476,
      "step": 730
    },
    {
      "epoch": 0.6635283568706568,
      "grad_norm": 0.04128843918442726,
      "learning_rate": 6.270388904188316e-05,
      "loss": 0.0475,
      "step": 740
    },
    {
      "epoch": 0.6724949562878278,
      "grad_norm": 0.03683158755302429,
      "learning_rate": 6.209554757554569e-05,
      "loss": 0.0473,
      "step": 750
    },
    {
      "epoch": 0.6814615557049989,
      "grad_norm": 0.036250513046979904,
      "learning_rate": 6.149744990376868e-05,
      "loss": 0.0474,
      "step": 760
    },
    {
      "epoch": 0.6904281551221699,
      "grad_norm": 0.06962655484676361,
      "learning_rate": 6.091007080761801e-05,
      "loss": 0.0473,
      "step": 770
    },
    {
      "epoch": 0.699394754539341,
      "grad_norm": 0.05191556364297867,
      "learning_rate": 6.033387655955471e-05,
      "loss": 0.0473,
      "step": 780
    },
    {
      "epoch": 0.708361353956512,
      "grad_norm": 0.020131884142756462,
      "learning_rate": 5.9769324553299176e-05,
      "loss": 0.0472,
      "step": 790
    },
    {
      "epoch": 0.717327953373683,
      "grad_norm": 0.08306022733449936,
      "learning_rate": 5.921686294074353e-05,
      "loss": 0.0472,
      "step": 800
    },
    {
      "epoch": 0.7262945527908541,
      "grad_norm": 0.043844226747751236,
      "learning_rate": 5.867693027620029e-05,
      "loss": 0.0472,
      "step": 810
    },
    {
      "epoch": 0.7352611522080251,
      "grad_norm": 0.016533061861991882,
      "learning_rate": 5.814995516826982e-05,
      "loss": 0.0472,
      "step": 820
    },
    {
      "epoch": 0.7442277516251962,
      "grad_norm": 0.026067541912198067,
      "learning_rate": 5.7636355939602826e-05,
      "loss": 0.047,
      "step": 830
    },
    {
      "epoch": 0.7531943510423672,
      "grad_norm": 0.032854899764060974,
      "learning_rate": 5.7136540294828066e-05,
      "loss": 0.0468,
      "step": 840
    },
    {
      "epoch": 0.7621609504595382,
      "grad_norm": 0.021438179537653923,
      "learning_rate": 5.6650904996908774e-05,
      "loss": 0.0469,
      "step": 850
    },
    {
      "epoch": 0.7711275498767093,
      "grad_norm": 0.026228973641991615,
      "learning_rate": 5.617983555218492e-05,
      "loss": 0.0466,
      "step": 860
    },
    {
      "epoch": 0.7800941492938803,
      "grad_norm": 0.1007259339094162,
      "learning_rate": 5.572370590435103e-05,
      "loss": 0.0469,
      "step": 870
    },
    {
      "epoch": 0.7890607487110514,
      "grad_norm": 0.023593323305249214,
      "learning_rate": 5.528287813761274e-05,
      "loss": 0.0469,
      "step": 880
    },
    {
      "epoch": 0.7980273481282224,
      "grad_norm": 0.02563568204641342,
      "learning_rate": 5.4857702189257607e-05,
      "loss": 0.0469,
      "step": 890
    },
    {
      "epoch": 0.8069939475453934,
      "grad_norm": 0.014295931905508041,
      "learning_rate": 5.444851557186843e-05,
      "loss": 0.0466,
      "step": 900
    },
    {
      "epoch": 0.8159605469625645,
      "grad_norm": 0.021384190768003464,
      "learning_rate": 5.405564310539939e-05,
      "loss": 0.0466,
      "step": 910
    },
    {
      "epoch": 0.8249271463797355,
      "grad_norm": 0.08972889184951782,
      "learning_rate": 5.367939665932798e-05,
      "loss": 0.0467,
      "step": 920
    },
    {
      "epoch": 0.8338937457969066,
      "grad_norm": 0.03622410446405411,
      "learning_rate": 5.332007490508722e-05,
      "loss": 0.0467,
      "step": 930
    },
    {
      "epoch": 0.8428603452140776,
      "grad_norm": 0.020698724314570427,
      "learning_rate": 5.297796307897463e-05,
      "loss": 0.0465,
      "step": 940
    },
    {
      "epoch": 0.8518269446312486,
      "grad_norm": 0.023252524435520172,
      "learning_rate": 5.2653332755726435e-05,
      "loss": 0.0465,
      "step": 950
    },
    {
      "epoch": 0.8607935440484197,
      "grad_norm": 0.031183291226625443,
      "learning_rate": 5.2346441632936516e-05,
      "loss": 0.0465,
      "step": 960
    },
    {
      "epoch": 0.8697601434655907,
      "grad_norm": 0.022752752527594566,
      "learning_rate": 5.205753332649112e-05,
      "loss": 0.0465,
      "step": 970
    },
    {
      "epoch": 0.8787267428827618,
      "grad_norm": 0.045100580900907516,
      "learning_rate": 5.178683717718213e-05,
      "loss": 0.0465,
      "step": 980
    },
    {
      "epoch": 0.8876933422999328,
      "grad_norm": 0.04917291924357414,
      "learning_rate": 5.15345680686521e-05,
      "loss": 0.0464,
      "step": 990
    },
    {
      "epoch": 0.8966599417171038,
      "grad_norm": 0.058094218373298645,
      "learning_rate": 5.130092625681555e-05,
      "loss": 0.0464,
      "step": 1000
    },
    {
      "epoch": 0.9056265411342749,
      "grad_norm": 0.01678050123155117,
      "learning_rate": 5.1086097210892126e-05,
      "loss": 0.0463,
      "step": 1010
    },
    {
      "epoch": 0.9145931405514459,
      "grad_norm": 0.026024527847766876,
      "learning_rate": 5.08902514661777e-05,
      "loss": 0.0463,
      "step": 1020
    },
    {
      "epoch": 0.923559739968617,
      "grad_norm": 0.0714842826128006,
      "learning_rate": 5.071354448867021e-05,
      "loss": 0.0462,
      "step": 1030
    },
    {
      "epoch": 0.932526339385788,
      "grad_norm": 0.061051592230796814,
      "learning_rate": 5.055611655165795e-05,
      "loss": 0.0461,
      "step": 1040
    },
    {
      "epoch": 0.9414929388029589,
      "grad_norm": 0.020300500094890594,
      "learning_rate": 5.041809262436797e-05,
      "loss": 0.0462,
      "step": 1050
    },
    {
      "epoch": 0.95045953822013,
      "grad_norm": 0.034607645124197006,
      "learning_rate": 5.0299582272763155e-05,
      "loss": 0.0461,
      "step": 1060
    },
    {
      "epoch": 0.959426137637301,
      "grad_norm": 0.09320272505283356,
      "learning_rate": 5.0200679572566765e-05,
      "loss": 0.0462,
      "step": 1070
    },
    {
      "epoch": 0.968392737054472,
      "grad_norm": 0.07122344523668289,
      "learning_rate": 5.012146303458337e-05,
      "loss": 0.046,
      "step": 1080
    },
    {
      "epoch": 0.9773593364716431,
      "grad_norm": 0.03456302359700203,
      "learning_rate": 5.0061995542375494e-05,
      "loss": 0.0461,
      "step": 1090
    },
    {
      "epoch": 0.9863259358888141,
      "grad_norm": 0.03854023665189743,
      "learning_rate": 5.002232430234548e-05,
      "loss": 0.046,
      "step": 1100
    },
    {
      "epoch": 0.9952925353059852,
      "grad_norm": 0.08441407233476639,
      "learning_rate": 5.000248080626219e-05,
      "loss": 0.0459,
      "step": 1110
    }
  ],
  "logging_steps": 10,
  "max_steps": 1115,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100.0,
  "total_flos": 1.9879065406144512e+17,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
