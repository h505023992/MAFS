{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9983397897066962,
  "eval_steps": 500,
  "global_step": 451,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002213613724405091,
      "grad_norm": 0.18912667036056519,
      "learning_rate": 9.999939346632437e-05,
      "loss": 0.1592,
      "step": 1
    },
    {
      "epoch": 0.02213613724405091,
      "grad_norm": 0.09095728397369385,
      "learning_rate": 9.993937090895101e-05,
      "loss": 0.1547,
      "step": 10
    },
    {
      "epoch": 0.04427227448810182,
      "grad_norm": 0.07687998563051224,
      "learning_rate": 9.975777770673855e-05,
      "loss": 0.139,
      "step": 20
    },
    {
      "epoch": 0.06640841173215274,
      "grad_norm": 0.05859246477484703,
      "learning_rate": 9.945610117982589e-05,
      "loss": 0.1159,
      "step": 30
    },
    {
      "epoch": 0.08854454897620365,
      "grad_norm": 0.06309018284082413,
      "learning_rate": 9.903580455810242e-05,
      "loss": 0.1015,
      "step": 40
    },
    {
      "epoch": 0.11068068622025456,
      "grad_norm": 0.05751777067780495,
      "learning_rate": 9.849892641773985e-05,
      "loss": 0.0896,
      "step": 50
    },
    {
      "epoch": 0.13281682346430548,
      "grad_norm": 0.050162434577941895,
      "learning_rate": 9.784807079343047e-05,
      "loss": 0.0824,
      "step": 60
    },
    {
      "epoch": 0.1549529607083564,
      "grad_norm": 0.036629606038331985,
      "learning_rate": 9.708639454796683e-05,
      "loss": 0.0758,
      "step": 70
    },
    {
      "epoch": 0.1770890979524073,
      "grad_norm": 0.050022777169942856,
      "learning_rate": 9.621759206042376e-05,
      "loss": 0.0716,
      "step": 80
    },
    {
      "epoch": 0.1992252351964582,
      "grad_norm": 0.03113289549946785,
      "learning_rate": 9.524587730721097e-05,
      "loss": 0.069,
      "step": 90
    },
    {
      "epoch": 0.22136137244050913,
      "grad_norm": 0.04174191132187843,
      "learning_rate": 9.417596342290811e-05,
      "loss": 0.0654,
      "step": 100
    },
    {
      "epoch": 0.24349750968456005,
      "grad_norm": 0.05967683717608452,
      "learning_rate": 9.301303984001968e-05,
      "loss": 0.0638,
      "step": 110
    },
    {
      "epoch": 0.26563364692861097,
      "grad_norm": 0.024880699813365936,
      "learning_rate": 9.176274711852887e-05,
      "loss": 0.0626,
      "step": 120
    },
    {
      "epoch": 0.28776978417266186,
      "grad_norm": 0.07259900122880936,
      "learning_rate": 9.043114958733564e-05,
      "loss": 0.0609,
      "step": 130
    },
    {
      "epoch": 0.3099059214167128,
      "grad_norm": 0.028941258788108826,
      "learning_rate": 8.902470593027671e-05,
      "loss": 0.0607,
      "step": 140
    },
    {
      "epoch": 0.3320420586607637,
      "grad_norm": 0.026115823537111282,
      "learning_rate": 8.755023785939521e-05,
      "loss": 0.0591,
      "step": 150
    },
    {
      "epoch": 0.3541781959048146,
      "grad_norm": 0.02842997945845127,
      "learning_rate": 8.60148970274046e-05,
      "loss": 0.0578,
      "step": 160
    },
    {
      "epoch": 0.37631433314886553,
      "grad_norm": 0.05660161375999451,
      "learning_rate": 8.442613033983243e-05,
      "loss": 0.0577,
      "step": 170
    },
    {
      "epoch": 0.3984504703929164,
      "grad_norm": 0.03732357919216156,
      "learning_rate": 8.279164383509117e-05,
      "loss": 0.0569,
      "step": 180
    },
    {
      "epoch": 0.42058660763696737,
      "grad_norm": 0.035191431641578674,
      "learning_rate": 8.111936530767e-05,
      "loss": 0.0571,
      "step": 190
    },
    {
      "epoch": 0.44272274488101826,
      "grad_norm": 0.036595288664102554,
      "learning_rate": 7.941740585573676e-05,
      "loss": 0.0558,
      "step": 200
    },
    {
      "epoch": 0.46485888212506915,
      "grad_norm": 0.03080720454454422,
      "learning_rate": 7.769402053965729e-05,
      "loss": 0.0549,
      "step": 210
    },
    {
      "epoch": 0.4869950193691201,
      "grad_norm": 0.039733730256557465,
      "learning_rate": 7.59575683422509e-05,
      "loss": 0.055,
      "step": 220
    },
    {
      "epoch": 0.509131156613171,
      "grad_norm": 0.025240479037165642,
      "learning_rate": 7.421647162498785e-05,
      "loss": 0.0542,
      "step": 230
    },
    {
      "epoch": 0.5312672938572219,
      "grad_norm": 0.023506728932261467,
      "learning_rate": 7.247917527677986e-05,
      "loss": 0.0547,
      "step": 240
    },
    {
      "epoch": 0.5534034311012729,
      "grad_norm": 0.023074299097061157,
      "learning_rate": 7.075410575350488e-05,
      "loss": 0.0533,
      "step": 250
    },
    {
      "epoch": 0.5755395683453237,
      "grad_norm": 0.03495008498430252,
      "learning_rate": 6.90496302069383e-05,
      "loss": 0.0532,
      "step": 260
    },
    {
      "epoch": 0.5976757055893747,
      "grad_norm": 0.027901293709874153,
      "learning_rate": 6.737401590132844e-05,
      "loss": 0.0525,
      "step": 270
    },
    {
      "epoch": 0.6198118428334256,
      "grad_norm": 0.03085099533200264,
      "learning_rate": 6.573539011445908e-05,
      "loss": 0.0529,
      "step": 280
    },
    {
      "epoch": 0.6419479800774764,
      "grad_norm": 0.023976588621735573,
      "learning_rate": 6.414170071769244e-05,
      "loss": 0.0527,
      "step": 290
    },
    {
      "epoch": 0.6640841173215274,
      "grad_norm": 0.0245970468968153,
      "learning_rate": 6.260067762619175e-05,
      "loss": 0.0518,
      "step": 300
    },
    {
      "epoch": 0.6862202545655783,
      "grad_norm": 0.03477320820093155,
      "learning_rate": 6.111979530630282e-05,
      "loss": 0.052,
      "step": 310
    },
    {
      "epoch": 0.7083563918096292,
      "grad_norm": 0.02722245641052723,
      "learning_rate": 5.970623652194613e-05,
      "loss": 0.0514,
      "step": 320
    },
    {
      "epoch": 0.7304925290536801,
      "grad_norm": 0.03247077018022537,
      "learning_rate": 5.8366857495860874e-05,
      "loss": 0.0512,
      "step": 330
    },
    {
      "epoch": 0.7526286662977311,
      "grad_norm": 0.05197964236140251,
      "learning_rate": 5.710815465468075e-05,
      "loss": 0.051,
      "step": 340
    },
    {
      "epoch": 0.774764803541782,
      "grad_norm": 0.04213376343250275,
      "learning_rate": 5.593623311913868e-05,
      "loss": 0.051,
      "step": 350
    },
    {
      "epoch": 0.7969009407858328,
      "grad_norm": 0.09648091346025467,
      "learning_rate": 5.4856777092233137e-05,
      "loss": 0.0507,
      "step": 360
    },
    {
      "epoch": 0.8190370780298838,
      "grad_norm": 0.043276868760585785,
      "learning_rate": 5.38750222889832e-05,
      "loss": 0.0507,
      "step": 370
    },
    {
      "epoch": 0.8411732152739347,
      "grad_norm": 0.034336622804403305,
      "learning_rate": 5.29957305414972e-05,
      "loss": 0.0504,
      "step": 380
    },
    {
      "epoch": 0.8633093525179856,
      "grad_norm": 0.041093502193689346,
      "learning_rate": 5.2223166702528495e-05,
      "loss": 0.0504,
      "step": 390
    },
    {
      "epoch": 0.8854454897620365,
      "grad_norm": 0.11705487966537476,
      "learning_rate": 5.156107795954379e-05,
      "loss": 0.0502,
      "step": 400
    },
    {
      "epoch": 0.9075816270060875,
      "grad_norm": 0.036983244121074677,
      "learning_rate": 5.1012675659637565e-05,
      "loss": 0.0506,
      "step": 410
    },
    {
      "epoch": 0.9297177642501383,
      "grad_norm": 0.03256984427571297,
      "learning_rate": 5.058061973344763e-05,
      "loss": 0.0503,
      "step": 420
    },
    {
      "epoch": 0.9518539014941892,
      "grad_norm": 0.23467174172401428,
      "learning_rate": 5.0267005793620946e-05,
      "loss": 0.0503,
      "step": 430
    },
    {
      "epoch": 0.9739900387382402,
      "grad_norm": 0.02208058349788189,
      "learning_rate": 5.0073354970406496e-05,
      "loss": 0.0499,
      "step": 440
    },
    {
      "epoch": 0.9961261759822911,
      "grad_norm": 0.04715275764465332,
      "learning_rate": 5.000060653367564e-05,
      "loss": 0.0496,
      "step": 450
    }
  ],
  "logging_steps": 10,
  "max_steps": 451,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100.0,
  "total_flos": 8.040769953516749e+16,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
